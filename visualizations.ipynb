{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "9b1b1ff0-6a51-3956-9a6e-633337519b1c",
        "_uuid": "cc3dd44b4de02db3595fe2dfb83b5219b6e57ae0"
      },
      "cell_type": "markdown",
      "source": "# Exoplanet Data Exploration\n\nHere are some of my initial attempts to look at the exoplanet datasets from Kepler. The dataset is highly unbalanced, so a fully automated analysis will be quite difficult. We also have to be careful since there are other effects such as rotating spots that might fake the kind of signal from an exoplanet.\n\nFirst, we'll load some packages and read in the dataset."
    },
    {
      "metadata": {
        "_cell_guid": "e1c08d33-9732-d7b3-f5a7-55c0547b5581",
        "_uuid": "eb623edb8211f9a19f0db61d2decd84a3f2f9f38",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport sklearn as sk\nimport scipy\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\ndf = pd.read_csv('../input/exoTrain.csv',index_col=0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "656cd2f1-fc96-3d2b-4d39-3f8c61ac32a5",
        "_uuid": "ab8f5e4770074eef3cec8591fdfa5bd63646928c"
      },
      "cell_type": "markdown",
      "source": "Now we'll look at the top few lines"
    },
    {
      "metadata": {
        "_cell_guid": "b16ab581-cf5f-7722-e1f5-13b5d3c98462",
        "_uuid": "81b1c11a944d814d592c9085644e733aeb6bfb23",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "d0beabfb-496c-f3ce-a499-af4e8b884763",
        "_uuid": "70c0709afb8547d23bd34ee1dde47d7e98b79fc7"
      },
      "cell_type": "markdown",
      "source": "Evidently, the exoplanets are located at the beginning of the dataset. Otherwise, this is just a bunch of numbers. Let's drop the label for now so it'll be easier to transform the data."
    },
    {
      "metadata": {
        "_cell_guid": "610aa65a-3926-26c4-b3a4-6b7cd1400665",
        "_uuid": "0a1e6fcecee5489fefd436daeac9a74b35a301d0",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "labels = df.LABEL\ndf = df.drop('LABEL',axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1681149c-f9f9-3032-0728-f04366b70a2d",
        "_uuid": "a8ca2578ab2dd221cabfdc07bcf1b2998e2997aa"
      },
      "cell_type": "markdown",
      "source": "# Statistics\n\nLet's look at some basic statistics."
    },
    {
      "metadata": {
        "_cell_guid": "363891fe-d22d-d7ea-fb37-aac19ace90ca",
        "_uuid": "c81b4553ff6a20d31553032aefe1e6cd70642cdc",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def stats_plots(df):\n    means = df.mean(axis=1)\n    medians = df.median(axis=1)\n    std = df.std(axis=1)\n    maxval = df.max(axis=1)\n    minval = df.min(axis=1)\n    skew = df.skew(axis=1)\n    fig = plt.figure(figsize=(12,8))\n    ax = fig.add_subplot(231)\n    ax.hist(means,alpha=0.8,bins=50)\n    ax.set_xlabel('Mean Intensity')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(232)\n    ax.hist(medians,alpha=0.8,bins=50)\n    ax.set_xlabel('Median Intensity')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(233)\n    ax.hist(std,alpha=0.8,bins=50)\n    ax.set_xlabel('Intensity Standard Deviation')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(234)\n    ax.hist(maxval,alpha=0.8,bins=50)\n    ax.set_xlabel('Maximum Intensity')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(235)\n    ax.hist(minval,alpha=0.8,bins=50)\n    ax.set_xlabel('Minimum Intensity')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(236)\n    ax.hist(skew,alpha=0.8,bins=50)\n    ax.set_xlabel('Intensity Skewness')\n    ax.set_ylabel('Num. of Stars')\n\nstats_plots(df)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "789380d3-7e37-7db0-ead3-ffee20e65580",
        "_uuid": "611146d72d0884213d2724b2ae0be91ba5f8f749"
      },
      "cell_type": "markdown",
      "source": "There are some major outliers here that we should remove. I'll leave that alone for now though.\n\nWhat happens if we pick more sensible axes and look at the exoplanet stars and the non-exoplanet stars?"
    },
    {
      "metadata": {
        "_cell_guid": "02c246b0-9b4f-2d22-15b9-161533597ebf",
        "_uuid": "cdc60dd96026dc582d39719e65477c0f1bf5458e",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def stats_plots_label(df):\n    means1 = df[labels==1].mean(axis=1)\n    medians1 = df[labels==1].median(axis=1)\n    std1 = df[labels==1].std(axis=1)\n    maxval1 = df[labels==1].max(axis=1)\n    minval1 = df[labels==1].min(axis=1)\n    skew1 = df[labels==1].skew(axis=1)\n    means2 = df[labels==2].mean(axis=1)\n    medians2 = df[labels==2].median(axis=1)\n    std2 = df[labels==2].std(axis=1)\n    maxval2 = df[labels==2].max(axis=1)\n    minval2 = df[labels==2].min(axis=1)\n    skew2 = df[labels==2].skew(axis=1)\n    fig = plt.figure(figsize=(12,8))\n    ax = fig.add_subplot(231)\n    ax.hist(means1,alpha=0.8,bins=50,color='b',normed=True,range=(-250,250))\n    ax.hist(means2,alpha=0.8,bins=50,color='r',normed=True,range=(-250,250))\n    ax.get_legend()\n    ax.set_xlabel('Mean Intensity')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(232)\n    ax.hist(medians1,alpha=0.8,bins=50,color='b',normed=True,range=(-0.1,0.1))\n    ax.hist(medians2,alpha=0.8,bins=50,color='r',normed=True,range=(-0.1,0.1))\n    ax.get_legend()\n\n    ax.set_xlabel('Median Intensity')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(233)    \n    ax.hist(std1,alpha=0.8,bins=50,normed=True,color='b',range=(0,4000))\n    ax.hist(std2,alpha=0.8,bins=50,normed=True,color='r',range=(0,4000))\n    ax.get_legend()\n\n    ax.set_xlabel('Intensity Standard Deviation')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(234)\n    ax.hist(maxval1,alpha=0.8,bins=50,normed=True,color='b',range=(-10000,50000))\n    ax.hist(maxval2,alpha=0.8,bins=50,normed=True,color='r',range=(-10000,50000))\n    ax.get_legend()\n\n    ax.set_xlabel('Maximum Intensity')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(235)\n    ax.hist(minval1,alpha=0.8,bins=50,normed=True,color='b',range=(-50000,10000))\n    ax.hist(minval2,alpha=0.8,bins=50,normed=True,color='r',range=(-50000,10000))\n    ax.get_legend()\n\n    ax.set_xlabel('Minimum Intensity')\n    ax.set_ylabel('Num. of Stars')\n    ax = fig.add_subplot(236)\n    ax.hist(skew1,alpha=0.8,bins=50,normed=True,color='b',range=(-40,60))\n    ax.hist(skew2,alpha=0.8,bins=50,normed=True,color='r',range=(-40,60)) \n    ax.get_legend()\n\n    ax.set_xlabel('Intensity Skewness')\n    ax.set_ylabel('Num. of Stars')\n\nstats_plots_label(df)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "05faf1ce-8d8c-88b6-52e8-87b0adbd5e3a",
        "_uuid": "5b1fc17e609b650454c34643663032f377d07788"
      },
      "cell_type": "markdown",
      "source": "The distributions look pretty similar except in the case of median intensity, where the data look like they're restricted to a limited number of values. The skewness is also a bit different, likely because exoplanets are associated with dips in the intensity. So what's going on with the median?"
    },
    {
      "metadata": {
        "_cell_guid": "3ad647b4-8673-abcf-2ed7-ef69e9a4663b",
        "_uuid": "afd50146fedcd7b84743d5a32b7f1438e6956dec",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df[labels==1].median(axis=1).describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "27cb0598-49cf-afbf-9120-809268221401",
        "_uuid": "b09aa363bf2dcbaf84909eea1deaa711de75ba4f"
      },
      "cell_type": "markdown",
      "source": "Clearly, there's something wrong there. It looks like the exoplanet data and non-exoplanet data were processed slightly differently. The median for non-exoplanet data seems to have been defined to be zero. This might make it difficult to build a useful classifier. right now."
    },
    {
      "metadata": {
        "_cell_guid": "d2f34a7e-7d0d-524d-2564-6be8e1f816fa",
        "_uuid": "39e579b64551c7f605c71fe701ae2bbcce65b3fd"
      },
      "cell_type": "markdown",
      "source": "# Visualizations of Intensity Time Series\n\nLet's first look at the data from all 37 exoplanet stars and an identical number of non-exoplanet stars so we can get some sense of what features we might want to look for."
    },
    {
      "metadata": {
        "_cell_guid": "f9aefa4e-9c09-a07b-f82d-85254c87a98a",
        "_uuid": "85f6a92e0704215d368e7f47758f9eace3ee8815",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(12,40))\nx = np.array(range(3197))\nfor i in range(37):\n    ax = fig.add_subplot(13,3,i+1)\n    ax.scatter(x,df[labels==2].iloc[i,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e33311b9-0426-f7b0-6845-b2b6998b257e",
        "_uuid": "b6fbf5d6cc945b8ccd5aa7ef3299220aeb205a68",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(12,40))\nx = np.array(range(3197))\nfor i in range(37):\n    ax = fig.add_subplot(13,3,i+1)\n    ax.scatter(x,df[labels==1].iloc[i,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5743db52-41d5-27b5-4e34-32ce6d7ab69f",
        "_uuid": "4f7c36cd6592863050d3b5918b5b413d21cf87e4"
      },
      "cell_type": "markdown",
      "source": "There's tons of features that we can see here. We see both longer-scale structure and wildly different amounts of seemingly random noise. If you zoom in, a lot of noise looks sinusoidal. We also see a lot of anomalous points, particularly at high intensity. The clearest exoplanet signatures are fairly regular downward spikes in the data. Let's look at one of these."
    },
    {
      "metadata": {
        "_cell_guid": "6b56cded-48c6-a966-eb70-4f48f1139d2f",
        "_uuid": "71fec75b33e7bfcd79d336daa270dc9b50316704",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(12,4))\nax = fig.add_subplot(121)\nplt.scatter(x,df[labels==2].iloc[35,:])\nax = fig.add_subplot(122)\nplt.scatter(np.array(range(500)),df[labels==2].iloc[35,:500])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "c9edb083-d00f-533e-6999-2572e09cc1ec",
        "_uuid": "ad113b8e2c6610dc43dbeed917b188bd28589073"
      },
      "cell_type": "markdown",
      "source": "On the plot on the right (zoomed in) we can clearly see a sinusoidal structure. There are also upward pulses in the plot on the left, particularly toward the end. Maybe these could be spots? Instrument noise is also a possibility (I would guess more likely).\n\nLess clear are some possible signals of an almost rectangular pulse visible on the more general structure. A couple that have this kind of feature are shown below. These don't necessarily repeat and will likely be much more difficult to find. One of these seems to even have both kinds of features."
    },
    {
      "metadata": {
        "_cell_guid": "2fc851ce-880d-2262-51e3-e724c7d01de6",
        "_uuid": "63a4bc8b92802dce660999b2233b76d1e676588d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(12,4))\nax = fig.add_subplot(121)\nplt.scatter(x,df[labels==2].iloc[18,:])\nax = fig.add_subplot(122)\nplt.scatter(x,df[labels==2].iloc[30,:])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "9f042aa5-a57d-65cd-23c4-0d863ab2c079",
        "_uuid": "e818d69a56323537d6b03306d6ad7597d324b99d"
      },
      "cell_type": "markdown",
      "source": "The plot on the left has a single larger dip and a bunch of fast dips. The one on the right seems to have two transits but also has a very unstable signal that will need to be accounted for. \n\nWe also see that the amount of noise isn't necessarily stable even within one signal. The data below show a star with an exoplanet that has both a complicated general structure and a great deal of noise toward the end. The exoplanet signal is not clear at all here, at least not without further processing of data."
    },
    {
      "metadata": {
        "_cell_guid": "42a1edae-fd67-d524-2950-60c14978a87b",
        "_uuid": "1013063e79931e29f19f27d69f44a7f1f84a83be",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(10,15))\nax = fig.add_subplot(311)\nax.scatter(x,df[labels==2].iloc[9,:])\nax = fig.add_subplot(312)\nax.scatter(np.array(range(2500,3000)),df[labels==2].iloc[9,2500:3000])\nax = fig.add_subplot(313)\nax.scatter(np.array(range(1200,1700)),df[labels==2].iloc[9,1200:1700])\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3609b695-5ff2-dbb5-a4f5-5a2a69513b2a",
        "_uuid": "5092e710698355dd23d4c2d1e0848cfbb6940992"
      },
      "cell_type": "markdown",
      "source": "The middle plot shows some samples toward the end. The noise has some strange structure. It's not sinusoidal, but it clearly repeates. Toward the middle, we can see a few dips that maybe could be from a planet. Noisier repeating structures are also visible here.\n\nI've mentioned a few issues with the data, so now let's try to do some data cleaning.\n\n# Data Processing\n\n## Outlier Removal\n\nFirst, remember that we saw a lot of high-valued outliers. Let's try to get rid of those.\n\nTo do this, I'll take the top 1% of data points and replace them with the mean of the 4 points on either side, as long as that value is lower. We're looking for dips in the data, so removing a few % shouldn't affect things much."
    },
    {
      "metadata": {
        "_cell_guid": "a6bacc94-f8ee-66ce-68d7-a049ae29af3a",
        "_uuid": "5b2ad3e1b666799d32a0c01a9317db27b268344c",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def reduce_upper_outliers(df,reduce = 0.01, half_width=4):\n    length = len(df.iloc[0,:])\n    remove = int(length*reduce)\n    for i in df.index.values:\n        values = df.loc[i,:]\n        sorted_values = values.sort_values(ascending = False)\n       # print(sorted_values[:30])\n        for j in range(remove):\n            idx = sorted_values.index[j]\n            #print(idx)\n            new_val = 0\n            count = 0\n            idx_num = int(idx[5:])\n            #print(idx,idx_num)\n            for k in range(2*half_width+1):\n                idx2 = idx_num + k - half_width\n                if idx2 <1 or idx2 >= length or idx_num == idx2:\n                    continue\n                new_val += values['FLUX-'+str(idx2)]\n                \n                count += 1\n            new_val /= count # count will always be positive here\n            #print(new_val)\n            if new_val < values[idx]: # just in case there's a few persistently high adjacent values\n                df.set_value(i,idx,new_val)\n        \n            \n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "4db28991-cc93-a08a-7c35-99df2feccbf3",
        "_uuid": "d0b39aacbda15232907f29e8d4822524df65c910"
      },
      "cell_type": "markdown",
      "source": "To make things a bit easier, I'll take two subsamples: The exoplanet set and 100 random samples from the non-exoplanet set.\n\nI'll run the outlier remover twice, altering 2% of the data points."
    },
    {
      "metadata": {
        "_cell_guid": "142a6177-e86e-3272-584e-dc968ea8e894",
        "_uuid": "de1ad84f2506643641f2a6d106c903f7f52ccb67",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_exo = df[labels==2]\ndf_non = df[labels==1]\ndf_non = df_non.sample(n=100,random_state=999)\nfor i in range(2):\n    df_exo = reduce_upper_outliers(df_exo)\nfor i in range(2):\n    df_non = reduce_upper_outliers(df_non)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1aec859a-472e-1e1d-e53e-73340744ea77",
        "_uuid": "cf836c57c7848a2f15a58775ad899ac33c838985"
      },
      "cell_type": "markdown",
      "source": "So what did that do? Well, we see below that we've removed the vast majority of the high-valued outliers. There are still some problem areas in a few of these, mostly due to having a series of nearby high points. There is also some clipping there, but as I've mentioned, this shouldn't give us too much trouble."
    },
    {
      "metadata": {
        "_cell_guid": "b9538173-41fd-2697-c883-5505664eb7f2",
        "_uuid": "896b581f72dc3deaa6d84885c92c54c33e523f33",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(12,40))\nx = np.array(range(3197))\nfor i in range(37):\n    ax = fig.add_subplot(13,3,i+1)\n    ax.scatter(x,df_exo.iloc[i,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "296ab1bf-7b71-0c6a-8408-0155b3613696",
        "_uuid": "92754fd5b47c4d0b579a84b0a1321bbf1ea34670",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(12,40))\nx = np.array(range(3197))\nfor i in range(37):\n    ax = fig.add_subplot(13,3,i+1)\n    ax.scatter(x,df_non.iloc[i,:])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "7e722bca-0131-2dcb-0b20-f6aa2c72f09e",
        "_uuid": "ee231743d156faf6e5f02559327faf909f8d574a"
      },
      "cell_type": "markdown",
      "source": "## Smoothing\n\nNow let's try to smooth the data. I'll do this in two steps:\n\nFirst, I'll run a pass with a fairly wide (41 samples) median filter. I also looked at a Gaussian FIR filter. I don't think the exact choice of this will matter much. The width sets the size of features that we want to select.\n\nThis first step is actually going to be used to remove features. I will run the filter and subtract it from the result. Here, any features that are wider than a few tens of samples will be removed, so this is a high-pass filter.\n\nI'll use a 4th order Savitzky-Golay filter (half-width of 10) as the second step. This is an interesting filter since it's an FIR version of running a polynomial least-squares fit at every point. That means that it doesn't just give estimates for the de-noised signal but also for some of the derivatives. I won't use that functionality right now. Again, there are tons of filters that can be used and many of them won't differ too much. I'll just run the filter here, so it will smooth the signals.\n\nHere, I'll plot these steps for several of the exoplanet stars. You'll see the original signal, the high-pass filtered signal, and finally the smoothed signal."
    },
    {
      "metadata": {
        "_cell_guid": "0f6a6767-f70c-0cc6-1160-b24c5b167052",
        "_uuid": "8fee9b0268001f21442a3b99c47037dbc2958aff",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from scipy.signal import savgol_filter\nfrom scipy.signal import gaussian\nfrom scipy.signal import medfilt\nfrom scipy.signal import lfilter\n\ntest = [0,7,11,12,31,34]\nnfigs = 2 * len(test)\nfig = plt.figure(figsize=[13,50])\ncount = 1\nfor i in test:\n    ax = fig.add_subplot(nfigs,3,count)\n    ax.scatter(np.array(range(len(df_exo.iloc[i,:]))),df_exo.iloc[i,:])\n    count += 1\n    y0 = medfilt(df_exo.iloc[i,:],41)\n    for idx in range(len(y0)):\n        y0[idx] = df_exo.iloc[i,idx] - y0[idx]\n    y1 = savgol_filter(y0,21,4,deriv=0)\n    ax = fig.add_subplot(nfigs,3,count)\n    count += 1\n    ax.scatter( np.array(range(len(y0))),y0)\n    ax.set_label('Sample')\n    ax.set_ylabel('Gaussian Smoothing')\n    ax.set_title('Exoplanet Star '+str(i))\n    \n    ax = fig.add_subplot(nfigs,3,count)\n    count += 1\n    ax.scatter( np.array(range(len(y1)-40)),y1[20:-20])\n    ax.set_label('Sample')\n    ax.set_ylabel('Savitzky-Golay Estimate, 1st derivative')\n    ax.set_title('Exoplanet Star '+str(i))\n    \nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "a9a27fc6-210c-15ab-04fb-6bf685041b9e",
        "_uuid": "238692987a07941935dbf6d1bffcfa14975e0dbb"
      },
      "cell_type": "markdown",
      "source": "You can see here that the first step removed a lot of the broader structure, while the second reduces the size of random noise. The signal is still not clear for the first and maybe last (the last is very noisy) stars. The 2nd, 3rd, and 4th are now extremely clear. The smoothing helped regularize the shape of the peaks, so while the shapes are now different, it will be very easy for a simple peak finder to find them.\n\nThe 5th star shows some interesting behavior. In the initial and high-pass-filtered data, we see what looks like a pretty regular structure of the exoplanet going by. However, in the smoothed signal we see that three of the transits are much clearerwhile the others maybe seem less clear. So, are there two kinds of transits here? Or are some of these dips not actually transits?\n\nRegardless, I'll now build a filter function and run it on my two small datasets."
    },
    {
      "metadata": {
        "_cell_guid": "2a6e655a-d26c-e8d0-fa62-185f776d1f4b",
        "_uuid": "97cdf7b5ba0c0c10657035564187a4a99cc5da2c",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def short_transit_filter(df):\n\n    length = df.shape[0]\n    output = []\n    for i in range(length):\n\n        y0 = medfilt(df.iloc[i,:],41)\n        for idx in range(len(y0)):\n            y0[idx] = df.iloc[i,idx] - y0[idx]\n        y1 = savgol_filter(y0,21,4,deriv=0) # remove edge effects\n        output.append(y1)\n    \n    return output\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e88cea87-e0e9-6c3f-4501-e981222cb217",
        "_uuid": "45b7bee20c587d2835c00344657e649560223add",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "out_exo = short_transit_filter(df_exo)\nout_non = short_transit_filter(df_non)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8e84cda6-0ad5-228d-073b-d1bd345cee6c",
        "_uuid": "4f207ccf29ed31665b049d6e75c139d9bed036af"
      },
      "cell_type": "markdown",
      "source": "Now, we can look at what we did to our data."
    },
    {
      "metadata": {
        "_cell_guid": "3e6981a8-ee85-761b-dff1-b9deaa12b55b",
        "_uuid": "f4d58dc369cf30c11da314a144de6602d2085dc4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(13,40))\nx = np.array(range(len(out_exo[0])-24))\nfor i in range(37):\n    ax = fig.add_subplot(13,3,i+1)\n    ax.scatter(x,out_exo[i][12:-12])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "91a0dd6a-2427-3eda-385f-0daa16fb7c5a",
        "_uuid": "5a2af2eb291e07dc2884fa2f4df763c1aa1a09a1"
      },
      "cell_type": "markdown",
      "source": "Here, we can see obvious exoplanet transits in about half of our data. We also see that the smoothing is clearly affected by outliers (see some of the upward peaks that have appeared). We may want to develop smarter outlier removers that look for local outliers as well."
    },
    {
      "metadata": {
        "_cell_guid": "de98bdc7-7468-5d4f-148d-a85150d122ba",
        "_uuid": "0a11b0eadc4de6b1e3c8cf0a0cdd4022f94f0c85",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(13,40))\nx = np.array(range(len(out_exo[0])-24))\nfor i in range(37):\n    ax = fig.add_subplot(13,3,i+1)\n    ax.scatter(x,out_non[i][12:-12])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ed7db954-2c89-0dd6-dc04-56c7d73bd2dd",
        "_uuid": "d0892f334a7ad49313b6174e94e846d44ed25a7a"
      },
      "cell_type": "markdown",
      "source": "In the non-exoplanet data we see downward spikes as well, but mostly isolated or at irregular intervals. If you look closely at the original data, many of these seem to be from single isolated data points. Maybe we should develop an outlier remover for downward spikes, but that might prove to be quite difficult if we don't want to remove our exoplanet events."
    },
    {
      "metadata": {
        "_cell_guid": "9f67bc98-2c51-1aff-6b74-09b22071ccb3",
        "_uuid": "b02f2c19fcf3cd64945a202b7e5f122416e6f5b3",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "## After filtering\n\ndf_exo_filt = pd.DataFrame(out_exo)\ndf_non_filt = pd.DataFrame(out_non)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "881e4707-197a-46b2-27b4-8c0a2bb6a232",
        "_uuid": "3bb9ad2c520fdbdc8608146f8535e25b9285b3b5"
      },
      "cell_type": "markdown",
      "source": "## Post-smoothing statistics\n\nNow let's see what happened to some of the basic statistics we looked at before."
    },
    {
      "metadata": {
        "_cell_guid": "34d44b33-736c-ab84-70fd-1a2f524dad06",
        "_uuid": "291e1fffe06a2aaca9191bdaa94b47a99ff57d6a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "means2 = df_exo_filt.mean(axis=1)\nstd2 = df_exo_filt.std(axis=1)\nmedians2 = df_exo_filt.median(axis=1)\nmeans1 = df_non_filt.mean(axis=1)\nstd1 = df_non_filt.std(axis=1)\nmedians1 = df_non_filt.median(axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1caaeaf1-1d6f-0235-a26c-9798d0fbcea9",
        "_uuid": "c5041ed00c8687a17e84247cda760aaf6a29dfda",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "fig = plt.figure(figsize=(10,10))\n\nax = fig.add_subplot(221)\nax.hist(means1,color='b',range=(-300,100),bins=20)\nax.hist(means2,color='r',range=(-300,100),bins=20)\nax.set_xlabel('Mean Intensity')\nax = fig.add_subplot(222)\nax.hist(medians1,color='b',range=(-50,50),bins=20)\nax.hist(medians2,color='r',range=(-50,50),bins=20)\nax.set_xlabel('Median Intensity')\nax = fig.add_subplot(223)\nax.hist(std1,color='b',range=(0,500),bins=10)\nax.hist(std2,color='r',range=(0,500),bins=10)\nax.set_xlabel('Intensity Std. Dev.')\n\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "56e81635-8e5a-0ab3-b2a2-4b4d89255948",
        "_uuid": "f7983696b497c7fd054eacd725b1bca76f151679"
      },
      "cell_type": "markdown",
      "source": "As we might have expected, our smoothing has caused significant reductions in the mean and median data for most of our data. The standard deviation also looks like it has been reduced substantially."
    },
    {
      "metadata": {
        "_cell_guid": "5087e4e0-37cb-9119-dc65-9f4ae2ee14f7",
        "_uuid": "8ab927ab2ca39a141686412bb9f05ed3aab21145"
      },
      "cell_type": "markdown",
      "source": "# Additional Work to Do\n\nThis just shows some visualizations and some basic processing steps. We haven't tried to classify anything yet. There's still a lot of processing that can be done. It may be useful to run several smoothing steps looking at different feature sizes. Once that's done, it might be good to then start data reduction. Taking FFTs of many samples may give us some information about any kind of instrument noise. If there are some characteristic frequencies of noise, we could try to filter them out.\n\nAutocorrelation or partial autocorrelation may be quite useful in helping find periodic features such as the short-duration, short-interval transits. \n\nWith such a small exoplanet sample, it may be impossible to achieve a very high purity sample. However, even getting a substantial reduction in non-exoplanet data could be useful. I also wonder if maybe neural nets can be enlisted to look for exoplanet-like features."
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "file_extension": ".py",
      "version": "3.6.0",
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python"
    },
    "_change_revision": 0,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "_is_fork": false
  },
  "nbformat": 4,
  "nbformat_minor": 1
}